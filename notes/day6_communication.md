

# Day 6 – Communication Reflection

- Built my first full ML mini-project using the Iris dataset with RandomForest.  
- Learned the Adapter pattern with example  
- Captured a leadership insight: adoption rate is as important as technical performance in AI product success.

# Points to remember - 
# Random Forest 

- A Random Forest is an ensemble learning algorithm.

- It builds many decision trees during training and then combines their outputs (via voting in classification, or averaging in regression).

- It’s called a “forest” because it’s literally a collection of many decision trees, and “random” because randomness is injected during training to make the trees diverse.

# Advantages

- High accuracy: Combines many weak learners (trees) into a strong learner.

- Robust to overfitting: Trees can overfit individually, but combining them reduces variance.

- Handles non-linear data well.

- Feature importance: Can tell you which features are most influential in classification.

# Disadvantages

- Less interpretable than a single decision tree.

- Slower when the forest has many trees.

- Memory intensive, since many trees are stored.

